#DATA
data_root: dataset/
classes: 4
modality: mri


#MODEL
arch: utnetv3
in_chan: 1
base_chan: 32
conv_block: 'BasicBlock'

down_scale: [[1,2,2], [1,2,2], [2,2,2], [2,2,2]] # coresponds to down1 down2 down3 down4
kernel_size: [[1,3,3], [1,3,3], [3,3,3], [3,3,3], [3,3,3]] # coresponds to inconv, down1, down2, down3, down4
norm: in
act: gelu
map_size: [2, 6, 6]
conv_num: [2,0,0,0, 0,0,2,2]
trans_num: [0,2,2,2, 2,2,0,0]
num_heads: [1,4,4,4, 4,4,1,1]
expansion: 4
fusion_depth: 2
fusion_dim: 256 #256
fusion_heads: 4
attn_drop: 0.
proj_drop: 0.
proj_type: 'depthwise'
rel_pos: False
se: True


#TRAIN
epochs: 150
training_size: [16, 256, 256] # training crop size
start_epoch: 0

aux_loss: False
aux_weight: [0.7, 0.3]

seed: 0
k_fold: 5

optimizer: adamw
base_lr: 0.001 #0.001
betas: [0.9, 0.999]
weight_decay: 0.05  # weight decay of SGD optimizer
weight: [0.5, 1, 1, 1]  # weitght of each class in the loss function
rlt: 1 # relation between CE and Dice loss
iter_per_epoch: 200


scale: [0.1, 0.3, 0.3]  # scale for data augmentation  0.1 0.3 0.3
rotate: [30, 0, 0] # rotation angle for data augmentation 
translate: [0, 0, 0]
gaussian_noise_std: 0.02
additive_brightness_std: 0.7
gamma_range: [0.5, 1.6]





#VALIDATION
ema: True
ema_alpha: 0.99
val_frequency: 10



#INFERENCE
sliding_window: True
window_size: [16, 256, 256]

#no idea
print_freq: 10